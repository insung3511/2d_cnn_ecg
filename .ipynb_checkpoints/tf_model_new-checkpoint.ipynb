{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # 그래픽 카드 둘로 쓰기 (두개 있을때, 하나만 있다면 0)\n",
    "# # gpu idx 를 0 또는 1 로 설정하시오\n",
    "# import tensorflow as tf \n",
    "# import os\n",
    "\n",
    "# os.environ[\"CUDA_DEVICE_ORDER\"]= \"PCI_BUS_ID\"\n",
    "# os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"0\" # gpu idx\n",
    "\n",
    "# tf.config.set_soft_device_placement(True)\n",
    "# tf.debugging.set_log_device_placement(True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU')]\n",
      "[name: \"/device:CPU:0\"\n",
      "device_type: \"CPU\"\n",
      "memory_limit: 268435456\n",
      "locality {\n",
      "}\n",
      "incarnation: 6414434732188536999\n",
      "xla_global_id: -1\n",
      ", name: \"/device:GPU:0\"\n",
      "device_type: \"GPU\"\n",
      "memory_limit: 5834643865\n",
      "locality {\n",
      "  bus_id: 1\n",
      "  links {\n",
      "  }\n",
      "}\n",
      "incarnation: 17765545383893213739\n",
      "physical_device_desc: \"device: 0, name: NVIDIA GeForce RTX 2070, pci bus id: 0000:02:00.0, compute capability: 7.5\"\n",
      "xla_global_id: 416903419\n",
      "]\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.python.client import device_lib \n",
    "import tensorflow as tf \n",
    "\n",
    "gpus = tf.config.experimental.list_physical_devices('GPU')\n",
    "if gpus:\n",
    "    try:\n",
    "        tf.config.experimental.set_memory_growth(gpus[0], True)\n",
    "    except RuntimeError as e:\n",
    "        print(e)\n",
    "        print(\"Got error idoit\")\n",
    "print(gpus)\n",
    "\n",
    "with tf.device('/device:GPU:0'):\n",
    "    print(device_lib.list_local_devices())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 경로에 폴더가 없으면 폴더 만들기\n",
    "import os\n",
    "\n",
    "def createDirectory(directory):\n",
    "    try:\n",
    "        if not os.path.exists(directory):\n",
    "            os.makedirs(directory)\n",
    "    except OSError:\n",
    "        print(\"Error: Failed to create the directory.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image, ImageOps\n",
    "from tqdm import tqdm\n",
    "import numpy as np\n",
    "import itertools\n",
    "import pathlib\n",
    "import cv2\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow import keras\n",
    "import tensorflow as tf\n",
    "\n",
    "EPOCH = 100\n",
    "KERNEL_SIZE = 3\n",
    "BATCH_SIZE = 128\n",
    "IMAGE_HEIGHT = 256\n",
    "IMAGE_WIDTH = 256\n",
    "\n",
    "DATA_PATH = \"./graph_data/\"\n",
    "\n",
    "def list_to_list(input_list):\n",
    "    input_list_to_list = list(itertools.chain(*input_list))\n",
    "    return input_list_to_list"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 데이터 불러오기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "graph_data\n",
      "112599\n"
     ]
    }
   ],
   "source": [
    "data_dir = pathlib.Path(DATA_PATH)\n",
    "print(data_dir)\n",
    "\n",
    "image_count = len(list(data_dir.glob('*/*.png')))\n",
    "print(image_count)\n",
    "\n",
    "f = list(data_dir.glob('F/*'))\n",
    "n = list(data_dir.glob('N/*'))\n",
    "q = list(data_dir.glob('Q/*'))\n",
    "s = list(data_dir.glob('S/*'))\n",
    "v = list(data_dir.glob('V/*'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 데이터 split\n",
    "## train, test, validation data 나누기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "parents_path = DATA_PATH"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Current path : ./graph_data/F\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████| 803/803 [00:00<00:00, 1217.49it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Current path : ./graph_data/N\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████| 90631/90631 [01:19<00:00, 1145.57it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Current path : ./graph_data/Q\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████| 11148/11148 [00:11<00:00, 1011.83it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Current path : ./graph_data/S\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████| 2781/2781 [00:02<00:00, 1034.15it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Current path : ./graph_data/V\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████| 7236/7236 [00:07<00:00, 1027.06it/s]\n"
     ]
    }
   ],
   "source": [
    "parents_path = DATA_PATH\n",
    "child_path = os.listdir(parents_path)\n",
    "\n",
    "npy_check_list = []\n",
    "\n",
    "temp_converted_img = list()\n",
    "temp_ann_list = list()\n",
    "X = list()\n",
    "y = list()\n",
    "\n",
    "for pic_path in (child_path):\n",
    "    current_path = os.listdir(parents_path + pic_path)\n",
    "    print(\"[INFO] Current path : \" + parents_path + pic_path)\n",
    "    for file_name in tqdm(current_path):\n",
    "        path_for_array = parents_path + pic_path + \"/\" + file_name\n",
    "\n",
    "        img = cv2.imread(path_for_array)\n",
    "        img = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "        img_resize = cv2.resize(img, dsize=(128, 128), interpolation=cv2.INTER_AREA)\n",
    "        temp_converted_img.append(img_resize / 255.0)\n",
    "        \n",
    "        check_ann = pic_path\n",
    "        \n",
    "        if check_ann == \"N\":            # Normal\n",
    "            temp_ann_list.append([1, 0, 0, 0, 0])\n",
    "        \n",
    "        elif check_ann == \"S\":          # Supra-ventricular\n",
    "            temp_ann_list.append([0, 1, 0, 0, 0])\n",
    "        \n",
    "        elif check_ann == \"V\":          # Ventricular\n",
    "            temp_ann_list.append([0, 0, 1, 0, 0])\n",
    "        \n",
    "        elif check_ann == \"F\":          # False alarm\n",
    "            temp_ann_list.append([0, 0, 0, 1, 0])\n",
    "        \n",
    "        else:                           # Unclassed \n",
    "            temp_ann_list.append([0, 0, 0, 0, 1])\n",
    "    \n",
    "        y.append(temp_ann_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "onehot_y = np.array(temp_ann_list)\n",
    "temp_converted_img = np.array(temp_converted_img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(temp_converted_img, onehot_y, test_size=0.33, random_state=42, shuffle=True)\n",
    "X_test, X_val, y_test, y_val = train_test_split(X_test, y_test, test_size=0.33, random_state=42, shuffle=True)\n",
    "\n",
    "print(\"[SIZE]\\t\\tNpX lenght : {}\\n\\t\\tNpY length : {}\".format(X_train.shape, y_train.shape))\n",
    "print(\"[SIZE]\\t\\tX_validation length : {}\\n\\t\\ty_validation length : {}\".format(X_val.shape, y_val.shape))\n",
    "print(\"[SIZE]\\t\\tX_test length : {}\\n\\t\\ty_test length : {}\".format(X_test.shape, y_test.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 랜덤으로 뽑아서 뿌려보기\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import random\n",
    "%matplotlib inline\n",
    "\n",
    "plt.figure(figsize=(30, 12))\n",
    "plt.suptitle(\"random pal, per PAL\", fontsize=18)\n",
    "n = 0\n",
    "random.seed(11)\n",
    "for i in random.sample(range(6480), 16):\n",
    "    ax = plt.subplot(5, 5, n+1)\n",
    "    plt.imshow(temp_converted_img[i] * 255.0, interpolation='nearest')\n",
    "    ax.set_title(str(onehot_y[i]))\n",
    "    n+=1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 모델 생성"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_size = (128, 128, 1)\n",
    "\n",
    "# models = keras.Sequential([\n",
    "#     # tf.keras.layers.experimental.preprocessing.Rescaling(1./255),\n",
    "#     layers.Conv2D(64, kernel_size=(3, 3), activation='relu', input_shape=input_size),\n",
    "#     layers.MaxPool2D(pool_size=(2, 2), strides=2),\n",
    "\n",
    "#     layers.Conv2D(128, kernel_size=(2, 2), activation='relu'),\n",
    "#     layers.MaxPool2D(pool_size=(2, 2), strides=2),\n",
    "\n",
    "#     layers.Conv2D(256, kernel_size=(3, 3), activation='relu'),\n",
    "#     layers.MaxPool2D(pool_size=(2, 2), strides=2),\n",
    "\n",
    "#     layers.Conv2D(512, kernel_size=(2, 2), activation='relu'),\n",
    "#     layers.MaxPool2D(pool_size=(2, 2), strides=2),\n",
    "\n",
    "#     layers.Flatten(),\n",
    "#     layers.Dropout(0.5),\n",
    "#     layers.Dense(4096, activation='relu'),\n",
    "#     layers.Dense(5, activation='softmax')\n",
    "# ])\n",
    "tf.config.set_soft_device_placement(True)\n",
    "tf.debugging.set_log_device_placement(True)\n",
    "\n",
    "kernel_init = tf.keras.initializers.glorot_uniform()\n",
    "bias_init = keras.initializers.Constant(value=0.2)\n",
    "\n",
    "def inception(x, filters_1, filters_1to3, filters_3, filters_1to5, filters_5, filters_pool_proj, kernel_init=kernel_init, bias_init=bias_init):\n",
    "    conv_1      = layers.Conv2D(filters_1,      (1, 1), padding='same', activation='relu', kernel_initializer=kernel_init, bias_initializer=bias_init)(x)\n",
    "    \n",
    "    conv_1to3   = layers.Conv2D(filters_1to3,   (1, 1), padding='same', activation='relu', kernel_initializer=kernel_init, bias_initializer=bias_init)(x)\n",
    "    conv_3      = layers.Conv2D(filters_3,      (3, 3), padding='same', activation='relu', kernel_initializer=kernel_init, bias_initializer=bias_init)(conv_1to3)\n",
    "    \n",
    "    conv_1to5   = layers.Conv2D(filters_1to5,   (1, 1), padding='same', activation='relu', kernel_initializer=kernel_init, bias_initializer=bias_init)(x)\n",
    "    conv_5      = layers.Conv2D(filters_5,      (5, 5), padding='same', activation='relu', kernel_initializer=kernel_init, bias_initializer=bias_init)(conv_1to5)\n",
    "    \n",
    "    max_pool    = layers.MaxPooling2D(pool_size=(3, 3), strides=1, padding='same')(x)\n",
    "    pool_proj   = layers.Conv2D(filters_pool_proj, (1, 1), padding='same', activation='relu', kernel_initializer=kernel_init, bias_initializer=bias_init)(max_pool)\n",
    "    \n",
    "    output      = layers.concatenate([conv_1, conv_3, conv_5, pool_proj])\n",
    "    return output\n",
    "\n",
    "input_layer = layers.Input(shape=(128, 128, 1))\n",
    "\n",
    "x = layers.Conv2D(64, kernel_size=(7, 7), strides=2, padding='same', activation='relu', kernel_initializer=kernel_init, bias_initializer=bias_init)(input_layer)\n",
    "x = layers.MaxPool2D(   pool_size=(3, 3), strides=2, padding='same')(x)\n",
    "x = layers.Conv2D(64, kernel_size=(1, 1), strides=1, padding='same', activation='relu', kernel_initializer=kernel_init, bias_initializer=bias_init)(x)\n",
    "x = layers.Conv2D(192,kernel_size=(3, 3), strides=1, padding='same', activation='relu', kernel_initializer=kernel_init, bias_initializer=bias_init)(x)\n",
    "x = layers.MaxPool2D(   pool_size=(3, 3), strides=2, padding='same')(x)\n",
    "\n",
    "x = inception(x, 64, 96, 128, 16, 32, 32)\n",
    "x = inception(x, 128, 128, 192, 32, 96, 64)\n",
    "x = layers.MaxPool2D(pool_size=(3, 3), strides=2)(x)\n",
    "\n",
    "x = inception(x, 192, 96, 208, 16, 48, 64)\n",
    "\n",
    "x1 = layers.AveragePooling2D(pool_size=(5, 5), strides=3)(x)\n",
    "x1 = layers.Conv2D(128, kernel_size=(1, 1), padding='same', activation='relu')(x1)\n",
    "x1 = layers.Flatten()(x1)\n",
    "x1 = layers.Dense(1024, activation='relu')(x1)\n",
    "x1 = layers.Dropout(0.2)(x1) #0.7\n",
    "x1 = layers.Dense(5, activation='softmax', name='aux_1')(x1)\n",
    "\n",
    "x = inception(x, 160, 112, 224, 24, 64, 64)\n",
    "x = inception(x, 128, 128, 256, 24, 64, 64)\n",
    "x = inception(x, 112, 144, 288, 32, 64, 64)\n",
    "\n",
    "x2 = layers.AveragePooling2D(pool_size=(5, 5), strides=3)(x)\n",
    "x2 = layers.Conv2D(128, kernel_size=(1, 1), padding='same', activation='relu')(x2)\n",
    "x2 = layers.Flatten()(x2)\n",
    "x2 = layers.Dense(1024, activation='relu')(x2)\n",
    "x2 = layers.Dropout(0.2)(x2) #0.7\n",
    "x2 = layers.Dense(5, activation='softmax', name='aux_2')(x2)\n",
    "\n",
    "x = inception(x, 256, 160, 320, 32, 128, 128)\n",
    "x = layers.MaxPool2D(pool_size=(3, 3), strides=2)(x)\n",
    "\n",
    "x = inception(x, 256, 160, 320, 32, 128, 128)\n",
    "x = inception(x, 384, 192, 384, 48, 128, 128)\n",
    "x = layers.GlobalAveragePooling2D()(x)\n",
    "x = layers.Dropout(0.2)(x) #0.4\n",
    "x = layers.Dense(5, activation='softmax', name='final')(x)\n",
    "\n",
    "googleNet = keras.Model(input_layer, [x, x1, x2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "googleNet.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "googleNet.compile(\n",
    "        optimizer='adam',\n",
    "        # loss=\"sparse_categorical_crossentropy\",\n",
    "        loss='categorical_crossentropy',\n",
    "        metrics=['accuracy']\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 콜백 설정"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 콜백 설정\n",
    "from keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "\n",
    "outDir = './cheakpoint/googleNet/' # 이 경로에 best 모델이 저장된다.\n",
    "model_names = outDir + 'weights-{final_accuracy:.4f}.h5'\n",
    "\n",
    "def get_callbacks(patience = 50): \n",
    "    with tf.device('/device:GPU:0'):\n",
    "        earlystop = EarlyStopping(monitor='final_accuracy', min_delta=0.0001, patience=patience)\n",
    "        model_checkpoint = ModelCheckpoint(model_names, monitor='final_accuracy', verbose=1, save_best_only=True, period = 1)\n",
    "\n",
    "        # callbacks = [earlystop, model_checkpoint]     # earlystop 사용하고 싶으면 이거 풀고 아래꺼 주석 처리\n",
    "        callbacks = [model_checkpoint]\n",
    "        return callbacks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 학습하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "callbacks = get_callbacks()\n",
    "tf.debugging.set_log_device_placement(True)\n",
    "\n",
    "with tf.device('/device:GPU:0'):\n",
    "    models_hist = googleNet.fit(\n",
    "        X_train,\n",
    "        y_train,\n",
    "        batch_size=BATCH_SIZE,\n",
    "        epochs=100,\n",
    "        validation_data=(X_val, y_val),\n",
    "        callbacks = [callbacks]\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 결과 시각화 하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 학습 된 모델의 학습 과정 시각화\n",
    "import matplotlib.pyplot as plt\n",
    "def plot_model__hist(hist):\n",
    "    path = './cheakpoint/lefms/' # loss, accuracy 그래프 저장할 path\n",
    "    createDirectory(path)\n",
    "\n",
    "    # loss 추이 그래프로 그려서 저장\n",
    "    plt.figure(figsize=(6,6))\n",
    "    plt.style.use(\"ggplot\")\n",
    "    plt.plot(hist.history['loss'], color='b', label=\"Training loss\")\n",
    "    plt.plot(hist.history['val_loss'], color='r', label=\"Validation loss\")\n",
    "    plt.savefig(path + 'model_loss_hist.png')\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "\n",
    "    # accuracy 추이 그래프로 그려서 저장\n",
    "    plt.figure(figsize=(6,6))\n",
    "    plt.style.use(\"ggplot\")\n",
    "    plt.plot(hist.history['final_accuracy'], color='b', label=\"Training accuracy\")\n",
    "    plt.plot(hist.history['val_final_accuracy'], color='r',label=\"Validation accuracy\")\n",
    "    plt.savefig(path + 'model_loss_hist.png')\n",
    "    plt.legend(loc = \"lower right\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_model__hist(models_hist)\n",
    "loss = googleNet.evaluate(X_val, y_val)\n",
    "# print(\"multi_model의 정확도: {:5.2f}%\".format(100*loss))\n",
    "print(loss)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 모델 불러와서 confusion matrix 그리기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.keras.backend.clear_session()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 모델 불러오기\n",
    "reconstructed_model = keras.models.load_model(\"./cheakpoint/googleNet/weights-0.8044.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 예측값 얻기\n",
    "with tf.device('cpu:0'):\n",
    "    y_pred = reconstructed_model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# one hat encoding 를 하나의 변수로 바꾸기\n",
    "new_y= []\n",
    "for val in y_test:\n",
    "    max = 0\n",
    "    cnt = 0\n",
    "    for idx, num in enumerate(val):\n",
    "        if max < num:\n",
    "            max = num\n",
    "            cnt = idx + 1\n",
    "    new_y.append(cnt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# one hat encoding 를 하나의 변수로 바꾸기\n",
    "new_y_pred = []\n",
    "for val in y_pred:\n",
    "    max = 0\n",
    "    cnt = 0\n",
    "    for idx, num in enumerate(val):\n",
    "        if max < num[-1]:\n",
    "            max = num[-1]\n",
    "            cnt = idx + 1\n",
    "    new_y_pred.append(cnt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 최종 정확도 산출\n",
    "with tf.device('/cpu:0'):\n",
    "    score = reconstructed_model.evaluate(X_test, y_test, verbose=1)\n",
    "print('정답률 = ', score[1],'loss=', score[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### confusion matrix 그리기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 개수 버전\n",
    "from sklearn.metrics import classification_report, confusion_matrix, precision_score, recall_score, f1_score\n",
    "import seaborn as sns\n",
    "\n",
    "cm2 = confusion_matrix(new_y, new_y_pred)\n",
    "sns.heatmap(cm2, annot = True, fmt = 'd', cmap= 'Reds')\n",
    "plt.xlabel('predict')\n",
    "plt.ylabel('real')\n",
    "plt.xticks([0.5, 1.5, 2.5, 3.5, 4.5], ['0 = N', '1 = S', '2 = V', '3 = F', '4 = Q'])\n",
    "plt.yticks([0.5, 1.5, 2.5, 3.5, 4.5], ['0 = N', '1 = S', '2 = V', '3 = F', '4 = Q'])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# percentile 버전\n",
    "total = np.sum(cm2, axis=1)\n",
    "cm2_percentile = cm2/total[:,None]\n",
    "sns.heatmap(np.round(cm2_percentile,3), annot = True, cmap= 'Reds')\n",
    "plt.xlabel('predict')\n",
    "plt.ylabel('real')\n",
    "plt.xticks([0.5, 1.5, 2.5, 3.5, 4.5], ['0 = N', '1 = S', '2 = V', '3 = F', '4 = Q'])\n",
    "plt.yticks([0.5, 1.5, 2.5, 3.5, 4.5], ['0 = N', '1 = S', '2 = V', '3 = F', '4 = Q'])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "confusion_matrix(new_y, new_y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# classification_report 그리기\n",
    "from sklearn.metrics import classification_report\n",
    "target_names = ['0 = N', '1 = S', '2 = V', '3 = F', '4 = Q']\n",
    "print(classification_report(new_y, new_y_pred, target_names=target_names))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "vscode": {
   "interpreter": {
    "hash": "a077222d77dfe082b8f1dd562ad70e458ac2ab76993a0b248ab0476e32e9e8dd"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
