{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 그래픽 카드 둘로 쓰기 (두개 있을때, 하나만 있다면 0)\n",
    "# gpu idx 를 0 또는 1 로 설정하시오\n",
    "import os\n",
    "os.environ[\"CUDA_DEVICE_ORDER\"]=\"PCI_BUS_ID\"\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] =\"{}\".format(1) # gpu idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 경로에 폴더가 없으면 폴더 만들기\n",
    "import os\n",
    "\n",
    "def createDirectory(directory):\n",
    "    try:\n",
    "        if not os.path.exists(directory):\n",
    "            os.makedirs(directory)\n",
    "    except OSError:\n",
    "        print(\"Error: Failed to create the directory.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import itertools\n",
    "import pathlib\n",
    "import cv2\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow import keras\n",
    "from tqdm import tqdm\n",
    "\n",
    "EPOCH = 100\n",
    "KERNEL_SIZE = 3\n",
    "BATCH_SIZE = 128\n",
    "IMAGE_HEIGHT = 256\n",
    "IMAGE_WIDTH = 256\n",
    "\n",
    "DATA_PATH = \"./graph_data/\"\n",
    "\n",
    "def list_to_list(input_list):\n",
    "    input_list_to_list = list(itertools.chain(*input_list))\n",
    "    return input_list_to_list"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 데이터 불러오기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "graph_data\n",
      "112599\n"
     ]
    }
   ],
   "source": [
    "data_dir = pathlib.Path(DATA_PATH)\n",
    "print(data_dir)\n",
    "\n",
    "image_count = len(list(data_dir.glob('*/*.png')))\n",
    "print(image_count)\n",
    "\n",
    "f = list(data_dir.glob('F/*'))\n",
    "n = list(data_dir.glob('N/*'))\n",
    "q = list(data_dir.glob('Q/*'))\n",
    "s = list(data_dir.glob('S/*'))\n",
    "v = list(data_dir.glob('V/*'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 데이터 split\n",
    "## train, test, validation data 나누기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Current path : ./graph_data/F\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 803/803 [00:07<00:00, 110.22it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Current path : ./graph_data/N\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 90631/90631 [14:41<00:00, 102.85it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Current path : ./graph_data/Q\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 11148/11148 [02:07<00:00, 87.36it/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Current path : ./graph_data/S\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2781/2781 [00:29<00:00, 95.26it/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Current path : ./graph_data/V\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 7236/7236 [01:15<00:00, 96.09it/s] \n"
     ]
    },
    {
     "ename": "MemoryError",
     "evalue": "Unable to allocate 41.2 GiB for an array with shape (5534466048,) and data type float64",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mMemoryError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[1;32mC:\\Users\\HILAB_~1\\AppData\\Local\\Temp/ipykernel_14344/2292971697.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     37\u001b[0m             \u001b[0mtemp_ann_list\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m4\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     38\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 39\u001b[1;33m     \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtemp_converted_img\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     40\u001b[0m     \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtemp_ann_list\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<__array_function__ internals>\u001b[0m in \u001b[0;36mappend\u001b[1;34m(*args, **kwargs)\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\HILAB_Labtop_02\\anaconda3\\lib\\site-packages\\numpy\\lib\\function_base.py\u001b[0m in \u001b[0;36mappend\u001b[1;34m(arr, values, axis)\u001b[0m\n\u001b[0;32m   4743\u001b[0m         \u001b[0mvalues\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mravel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   4744\u001b[0m         \u001b[0maxis\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0marr\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mndim\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 4745\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0mconcatenate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0marr\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalues\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0maxis\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   4746\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   4747\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<__array_function__ internals>\u001b[0m in \u001b[0;36mconcatenate\u001b[1;34m(*args, **kwargs)\u001b[0m\n",
      "\u001b[1;31mMemoryError\u001b[0m: Unable to allocate 41.2 GiB for an array with shape (5534466048,) and data type float64"
     ]
    }
   ],
   "source": [
    "parents_path = DATA_PATH\n",
    "child_path = os.listdir(parents_path)\n",
    "\n",
    "temp_converted_img = list()\n",
    "temp_ann_list = list()\n",
    "converted_img = list()\n",
    "X = np.array(list())\n",
    "y = np.array(list())\n",
    "\n",
    "for pic_path in (child_path):\n",
    "    current_path = os.listdir(parents_path + pic_path)\n",
    "    print(\"[INFO] Current path : \" + parents_path + pic_path)\n",
    "    for file_name in tqdm(current_path):\n",
    "        path_for_array = parents_path + pic_path + \"/\" + file_name\n",
    "        \n",
    "        img_array = np.fromfile(path_for_array, np.uint8)\n",
    "        img = cv2.imdecode(img_array, cv2.IMREAD_COLOR)\n",
    "        img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "        img_resize = cv2.resize(img, dsize=(128, 128), interpolation=cv2.INTER_AREA)\n",
    "        temp_converted_img.append(img_resize / 255.0)\n",
    "        \n",
    "        check_ann = pic_path\n",
    "        \n",
    "        if check_ann == \"N\":            # Normal\n",
    "            temp_ann_list.append(0)\n",
    "        \n",
    "        elif check_ann == \"S\":          # Supra-ventricular\n",
    "            temp_ann_list.append(1)\n",
    "        \n",
    "        elif check_ann == \"V\":          # Ventricular\n",
    "            temp_ann_list.append(2)\n",
    "        \n",
    "        elif check_ann == \"F\":          # False alarm\n",
    "            temp_ann_list.append(3)\n",
    "        \n",
    "        else:                           # Unclassed \n",
    "            temp_ann_list.append(4)\n",
    "    \n",
    "    np.append(X, temp_converted_img)\n",
    "    np.append(y, temp_ann_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"[SIZE]\\t\\tOriginal X size : {}\\n\\t\\tOriginal y size : {}\".format(X, y))\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33, random_state=42, shuffle=True)\n",
    "X_test, X_val, y_test, y_val = train_test_split(X_test, y_test, test_size=0.33, random_state=42, shuffle=True )\n",
    "\n",
    "npx = np.array(X_train)\n",
    "npy = np.array(y_train)\n",
    "npx_vali = np.array(X_val)\n",
    "npy_vali = np.array(y_val)\n",
    "npx_test = np.array(X_test)\n",
    "npy_test = np.array(y_test)\n",
    "\n",
    "print(\"[SIZE]\\t\\tNpX lenght : {}\\n\\t\\tNpY length : {}\".format(npx.shape, npy.shape))\n",
    "print(\"[SIZE]\\t\\tX_validation length : {}\\n\\t\\ty_validation length : {}\".format(npx_vali.shape, npy_vali.shape))\n",
    "print(\"[SIZE]\\t\\tX_test length : {}\\n\\t\\ty_test length : {}\".format(npx_test.shape, npy_test.shape))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 모델 생성"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_size = (128, 128, 1)\n",
    "\n",
    "models = keras.Sequential([\n",
    "    # tf.keras.layers.experimental.preprocessing.Rescaling(1./255),\n",
    "    layers.Conv2D(64, kernel_size=(3, 3), activation='relu', input_shape=input_size),\n",
    "    layers.MaxPool2D(pool_size=(2, 2), strides=2),\n",
    "\n",
    "    layers.Conv2D(128, kernel_size=(2, 2), activation='relu'),\n",
    "    layers.MaxPool2D(pool_size=(2, 2), strides=2),\n",
    "\n",
    "    layers.Conv2D(256, kernel_size=(3, 3), activation='relu'),\n",
    "    layers.MaxPool2D(pool_size=(2, 2), strides=2),\n",
    "\n",
    "    layers.Conv2D(512, kernel_size=(2, 2), activation='relu'),\n",
    "    layers.MaxPool2D(pool_size=(2, 2), strides=2),\n",
    "\n",
    "    layers.Flatten(),\n",
    "    layers.Dropout(0.5),\n",
    "    layers.Dense(4096, activation='relu'),\n",
    "    layers.Dense(5, activation='softmax')\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "models.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "models.compile(\n",
    "        optimizer='adam',\n",
    "        loss=\"sparse_categorical_crossentropy\",\n",
    "        # loss='categorical_crossentropy',\n",
    "        metrics=['accuracy']\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 콜백 설정"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 콜백 설정\n",
    "from keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "\n",
    "outDir = './cheakpoint/lefms_model/' # 이 경로에 best 모델이 저장된다.\n",
    "model_names = outDir + 'weights-{val_accuracy:.4f}.h5'\n",
    "\n",
    "def get_callbacks(patience = 50):\n",
    "    earlystop = EarlyStopping(monitor='val_accuracy', min_delta=0.0001, patience=patience)\n",
    "    model_checkpoint = ModelCheckpoint(model_names, monitor='val_accuracy', verbose=1, save_best_only=True, period = 1)\n",
    "  \n",
    "    # callbacks = [earlystop, model_checkpoint]     # earlystop 사용하고 싶으면 이거 풀고 아래꺼 주석 처리\n",
    "    callbacks = [model_checkpoint]\n",
    "    return callbacks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 학습하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "callbacks = get_callbacks()\n",
    "\n",
    "models_hist = models.fit(\n",
    "    X_train,\n",
    "    y_train,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    epochs=EPOCH,\n",
    "    validation_data=(X_val, y_val),\n",
    "    callbacks = [callbacks]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 결과 시각화 하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 학습 된 모델의 학습 과정 시각화\n",
    "import matplotlib.pyplot as plt\n",
    "def plot_model__hist(hist):\n",
    "    path = './cheakpoint/lefms/' # loss, accuracy 그래프 저장할 path\n",
    "    createDirectory(path)\n",
    "\n",
    "    # loss 추이 그래프로 그려서 저장\n",
    "    plt.figure(figsize=(6,6))\n",
    "    plt.style.use(\"ggplot\")\n",
    "    plt.plot(hist.history['loss'], color='b', label=\"Training loss\")\n",
    "    plt.plot(hist.history['val_loss'], color='r', label=\"Validation loss\")\n",
    "    plt.savefig(path + 'model_loss_hist.png')\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "\n",
    "    # accuracy 추이 그래프로 그려서 저장\n",
    "    plt.figure(figsize=(6,6))\n",
    "    plt.style.use(\"ggplot\")\n",
    "    plt.plot(hist.history['accuracy'], color='b', label=\"Training accuracy\")\n",
    "    plt.plot(hist.history['val_accuracy'], color='r',label=\"Validation accuracy\")\n",
    "    plt.savefig(path + 'model_loss_hist.png')\n",
    "    plt.legend(loc = \"lower right\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_model__hist(models_hist)\n",
    "loss,acc = models.evaluate(val_ds, verbose=2)\n",
    "print(\"multi_model의 정확도: {:5.2f}%\".format(100*acc))\n",
    "print(\"multi_model의 Loss: {}\".format(loss))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 모델 불러와서 confusion matrix 그리기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 모델 불러오기\n",
    "reconstructed_model = keras.models.load_model(\"./cheakpoint/lefms_model/weights-0.9924.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 예측값 얻기\n",
    "y_pred = reconstructed_model.predict(val_ds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# one hat encoding 를 하나의 변수로 바꾸기\n",
    "new_y= []\n",
    "for val in y_test:\n",
    "    max = 0\n",
    "    cnt = 0\n",
    "    for idx, num in enumerate(val):\n",
    "        if max < num:\n",
    "            max = num\n",
    "            cnt = idx + 1\n",
    "    new_y.append(cnt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# one hat encoding 를 하나의 변수로 바꾸기\n",
    "new_y_pred = []\n",
    "for val in y_pred:\n",
    "    max = 0\n",
    "    cnt = 0\n",
    "    for idx, num in enumerate(val):\n",
    "        if max < num:\n",
    "            max = num\n",
    "            cnt = idx + 1\n",
    "    new_y_pred.append(cnt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 최종 정확도 산출\n",
    "score = reconstructed_model.evaluate(X_test, y_test, verbose=1)\n",
    "print('정답률 = ', score[1],'loss=', score[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### confusion matrix 그리기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 개수 버전\n",
    "from sklearn.metrics import classification_report, confusion_matrix, precision_score, recall_score, f1_score\n",
    "import seaborn as sns\n",
    "\n",
    "cm2 = confusion_matrix(new_y, new_y_pred)\n",
    "sns.heatmap(cm2, annot = True, fmt = 'd', cmap= 'Reds')\n",
    "plt.xlabel('predict')\n",
    "plt.ylabel('real')\n",
    "plt.xticks([0.5, 1.5, 2.5, 3.5, 4.5], ['0 = N', '1 = S', '2 = V', '3 = F', '4 = Q'])\n",
    "plt.yticks([0.5, 1.5, 2.5, 3.5, 4.5], ['0 = N', '1 = S', '2 = V', '3 = F', '4 = Q'])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# percentile 버전\n",
    "total = np.sum(cm2, axis=1)\n",
    "cm2_percentile = cm2/total[:,None]\n",
    "sns.heatmap(np.round(cm2_percentile,3), annot = True, cmap= 'Reds')\n",
    "plt.xlabel('predict')\n",
    "plt.ylabel('real')\n",
    "plt.xticks([0.5, 1.5, 2.5, 3.5, 4.5], ['0 = N', '1 = S', '2 = V', '3 = F', '4 = Q'])\n",
    "plt.yticks([0.5, 1.5, 2.5, 3.5, 4.5], ['0 = N', '1 = S', '2 = V', '3 = F', '4 = Q'])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "confusion_matrix(new_y, new_y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# classification_report 그리기\n",
    "from sklearn.metrics import classification_report\n",
    "target_names = ['0 = N', '1 = S', '2 = V', '3 = F', '4 = Q']\n",
    "print(classification_report(new_y, new_y_pred, target_names=target_names))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.7 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "6c3cabcf2f29820bdd7faae982b59d335e0d215fb5382d93f3312fa3292e9b7f"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
