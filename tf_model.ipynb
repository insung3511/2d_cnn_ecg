{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 그래픽 카드 둘로 쓰기 (두개 있을때, 하나만 있다면 0)\n",
    "# gpu idx 를 0 또는 1 로 설정하시오\n",
    "import os\n",
    "os.environ[\"CUDA_DEVICE_ORDER\"]=\"PCI_BUS_ID\"\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] =\"{}\".format(1) # gpu idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 경로에 폴더가 없으면 폴더 만들기\n",
    "import os\n",
    "\n",
    "def createDirectory(directory):\n",
    "    try:\n",
    "        if not os.path.exists(directory):\n",
    "            os.makedirs(directory)\n",
    "    except OSError:\n",
    "        print(\"Error: Failed to create the directory.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import itertools\n",
    "import pathlib\n",
    "import cv2\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow import keras\n",
    "from tqdm import tqdm\n",
    "\n",
    "EPOCH = 100\n",
    "KERNEL_SIZE = 3\n",
    "BATCH_SIZE = 128\n",
    "IMAGE_HEIGHT = 256\n",
    "IMAGE_WIDTH = 256\n",
    "\n",
    "DATA_PATH = \"./graph_data/\"\n",
    "\n",
    "def list_to_list(input_list):\n",
    "    input_list_to_list = list(itertools.chain(*input_list))\n",
    "    return input_list_to_list"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 데이터 불러오기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "graph_data\n",
      "112599\n"
     ]
    }
   ],
   "source": [
    "data_dir = pathlib.Path(DATA_PATH)\n",
    "print(data_dir)\n",
    "\n",
    "image_count = len(list(data_dir.glob('*/*.png')))\n",
    "print(image_count)\n",
    "\n",
    "f = list(data_dir.glob('F/*'))\n",
    "n = list(data_dir.glob('N/*'))\n",
    "q = list(data_dir.glob('Q/*'))\n",
    "s = list(data_dir.glob('S/*'))\n",
    "v = list(data_dir.glob('V/*'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 데이터 split\n",
    "## train, test, validation data 나누기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Current path : ./graph_data/F\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 803/803 [00:09<00:00, 87.58it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Current path : ./graph_data/N\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 30%|███       | 27276/90631 [05:53<14:33, 72.49it/s]  "
     ]
    }
   ],
   "source": [
    "parents_path = DATA_PATH\n",
    "child_path = os.listdir(parents_path)\n",
    "\n",
    "temp_converted_img = list()\n",
    "converted_img = list()\n",
    "\n",
    "for pic_path in (child_path):\n",
    "    current_path = os.listdir(parents_path + pic_path)\n",
    "    print(\"[INFO] Current path : \" + parents_path + pic_path)\n",
    "    for file_name in tqdm(current_path):\n",
    "        path_for_array = parents_path + pic_path + \"/\" + file_name\n",
    "        \n",
    "        img_array = np.fromfile(path_for_array, np.uint8)\n",
    "        img = cv2.imdecode(img_array, cv2.IMREAD_COLOR)\n",
    "        img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "        img_resize = cv2.resize(img, dsize=(256, 256), interpolation=cv2.INTER_AREA)\n",
    "        temp_converted_img.append(img_resize / 255.0)\n",
    "    converted_img.append(temp_converted_img)\n",
    "\n",
    "converted_img = np.array(converted_img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(converted_img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 112599 files belonging to 5 classes.\n",
      "Using 90080 files for training.\n"
     ]
    }
   ],
   "source": [
    "train_ds = keras.preprocessing.image_dataset_from_directory(\n",
    "    data_dir,\n",
    "    validation_split=0.2,\n",
    "    subset=\"training\",\n",
    "    label_mode='int',\n",
    "    # label_mode='categorical',\n",
    "    color_mode='grayscale',\n",
    "    seed=1234,\n",
    "    image_size=(IMAGE_HEIGHT, IMAGE_WIDTH),\n",
    "    batch_size=BATCH_SIZE,\n",
    "    shuffle=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 112599 files belonging to 5 classes.\n",
      "Using 22519 files for validation.\n"
     ]
    }
   ],
   "source": [
    "val_ds = keras.preprocessing.image_dataset_from_directory(\n",
    "    data_dir,\n",
    "    validation_split=0.2,\n",
    "    subset=\"validation\",\n",
    "    label_mode='int',\n",
    "    # label_mode='categorical',\n",
    "    color_mode='grayscale',\n",
    "    seed=1234,\n",
    "    image_size=(IMAGE_HEIGHT, IMAGE_WIDTH),\n",
    "    batch_size=BATCH_SIZE,\n",
    "    shuffle=True\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 모델 생성"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_size = (256, 256, 1)\n",
    "\n",
    "models = keras.Sequential([\n",
    "    # tf.keras.layers.experimental.preprocessing.Rescaling(1./255),\n",
    "    layers.Conv2D(64, kernel_size=(3, 3), activation='relu', input_shape=input_size),\n",
    "    layers.MaxPool2D(pool_size=(2, 2), strides=2),\n",
    "\n",
    "    layers.Conv2D(128, kernel_size=(2, 2), activation='relu', input_shape=input_size),\n",
    "    layers.MaxPool2D(pool_size=(2, 2), strides=2),\n",
    "\n",
    "    layers.Conv2D(256, kernel_size=(3, 3), activation='relu', input_shape=input_size),\n",
    "    layers.MaxPool2D(pool_size=(2, 2), strides=2),\n",
    "\n",
    "    layers.Conv2D(512, kernel_size=(2, 2), activation='relu', input_shape=input_size),\n",
    "    layers.MaxPool2D(pool_size=(2, 2), strides=2),\n",
    "\n",
    "    layers.Flatten(),\n",
    "    layers.Dropout(0.5),\n",
    "    layers.Dense(4096, activation='relu'),\n",
    "    layers.Dense(5, activation='softmax')\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d (Conv2D)             (None, 254, 254, 64)      640       \n",
      "                                                                 \n",
      " max_pooling2d (MaxPooling2D  (None, 127, 127, 64)     0         \n",
      " )                                                               \n",
      "                                                                 \n",
      " conv2d_1 (Conv2D)           (None, 126, 126, 128)     32896     \n",
      "                                                                 \n",
      " max_pooling2d_1 (MaxPooling  (None, 63, 63, 128)      0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " conv2d_2 (Conv2D)           (None, 61, 61, 256)       295168    \n",
      "                                                                 \n",
      " max_pooling2d_2 (MaxPooling  (None, 30, 30, 256)      0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " conv2d_3 (Conv2D)           (None, 29, 29, 512)       524800    \n",
      "                                                                 \n",
      " max_pooling2d_3 (MaxPooling  (None, 14, 14, 512)      0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " flatten (Flatten)           (None, 100352)            0         \n",
      "                                                                 \n",
      " dropout (Dropout)           (None, 100352)            0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 4096)              411045888 \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 5)                 20485     \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 411,919,877\n",
      "Trainable params: 411,919,877\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "models.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "models.compile(\n",
    "        optimizer='adam',\n",
    "        loss=\"sparse_categorical_crossentropy\",\n",
    "        # loss='categorical_crossentropy',\n",
    "        metrics=['accuracy']\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 콜백 설정"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 콜백 설정\n",
    "from keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "\n",
    "outDir = './cheakpoint/lefms_model/' # 이 경로에 best 모델이 저장된다.\n",
    "model_names = outDir + 'weights-{val_accuracy:.4f}.h5'\n",
    "\n",
    "def get_callbacks(patience = 50):\n",
    "    earlystop = EarlyStopping(monitor='val_accuracy', min_delta=0.0001, patience=patience)\n",
    "    model_checkpoint = ModelCheckpoint(model_names, monitor='val_accuracy', verbose=1, save_best_only=True, period = 1)\n",
    "  \n",
    "    # callbacks = [earlystop, model_checkpoint]     # earlystop 사용하고 싶으면 이거 풀고 아래꺼 주석 처리\n",
    "    callbacks = [model_checkpoint]\n",
    "    return callbacks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 학습하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of batches seen.\n",
      "Epoch 1/100\n",
      "704/704 [==============================] - ETA: 0s - loss: 8.0787 - accuracy: 0.9022\n",
      "Epoch 1: val_accuracy improved from -inf to 0.96736, saving model to ./cheakpoint/lefms_model\\weights-0.9674.h5\n",
      "704/704 [==============================] - 5848s 8s/step - loss: 8.0787 - accuracy: 0.9022 - val_loss: 0.1282 - val_accuracy: 0.9674\n",
      "Epoch 2/100\n",
      "704/704 [==============================] - ETA: 0s - loss: 0.1072 - accuracy: 0.9679\n",
      "Epoch 2: val_accuracy improved from 0.96736 to 0.97766, saving model to ./cheakpoint/lefms_model\\weights-0.9777.h5\n",
      "704/704 [==============================] - 5822s 8s/step - loss: 0.1072 - accuracy: 0.9679 - val_loss: 0.0753 - val_accuracy: 0.9777\n",
      "Epoch 3/100\n",
      "704/704 [==============================] - ETA: 0s - loss: 0.0738 - accuracy: 0.9775\n",
      "Epoch 3: val_accuracy improved from 0.97766 to 0.98126, saving model to ./cheakpoint/lefms_model\\weights-0.9813.h5\n",
      "704/704 [==============================] - 5817s 8s/step - loss: 0.0738 - accuracy: 0.9775 - val_loss: 0.0609 - val_accuracy: 0.9813\n",
      "Epoch 4/100\n",
      "704/704 [==============================] - ETA: 0s - loss: 0.0561 - accuracy: 0.9828\n",
      "Epoch 4: val_accuracy improved from 0.98126 to 0.98241, saving model to ./cheakpoint/lefms_model\\weights-0.9824.h5\n",
      "704/704 [==============================] - 5829s 8s/step - loss: 0.0561 - accuracy: 0.9828 - val_loss: 0.0621 - val_accuracy: 0.9824\n",
      "Epoch 5/100\n",
      "704/704 [==============================] - ETA: 0s - loss: 0.0470 - accuracy: 0.9852\n",
      "Epoch 5: val_accuracy improved from 0.98241 to 0.98370, saving model to ./cheakpoint/lefms_model\\weights-0.9837.h5\n",
      "704/704 [==============================] - 5799s 8s/step - loss: 0.0470 - accuracy: 0.9852 - val_loss: 0.0630 - val_accuracy: 0.9837\n",
      "Epoch 6/100\n",
      "704/704 [==============================] - ETA: 0s - loss: 0.0390 - accuracy: 0.9872\n",
      "Epoch 6: val_accuracy did not improve from 0.98370\n",
      "704/704 [==============================] - 5800s 8s/step - loss: 0.0390 - accuracy: 0.9872 - val_loss: 0.0612 - val_accuracy: 0.9837\n",
      "Epoch 7/100\n",
      "516/704 [====================>.........] - ETA: 24:09 - loss: 0.0348 - accuracy: 0.9891"
     ]
    }
   ],
   "source": [
    "callbacks = get_callbacks()\n",
    "\n",
    "models_hist = models.fit(\n",
    "    train_ds,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    epochs=EPOCH,\n",
    "    validation_data=(val_ds),\n",
    "    callbacks = [callbacks]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 결과 시각화 하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 학습 된 모델의 학습 과정 시각화\n",
    "import matplotlib.pyplot as plt\n",
    "def plot_model__hist(hist):\n",
    "    path = './cheakpoint/lefms/' # loss, accuracy 그래프 저장할 path\n",
    "    createDirectory(path)\n",
    "\n",
    "    # loss 추이 그래프로 그려서 저장\n",
    "    plt.figure(figsize=(6,6))\n",
    "    plt.style.use(\"ggplot\")\n",
    "    plt.plot(hist.history['loss'], color='b', label=\"Training loss\")\n",
    "    plt.plot(hist.history['val_loss'], color='r', label=\"Validation loss\")\n",
    "    plt.savefig(path + 'model_loss_hist.png')\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "\n",
    "    # accuracy 추이 그래프로 그려서 저장\n",
    "    plt.figure(figsize=(6,6))\n",
    "    plt.style.use(\"ggplot\")\n",
    "    plt.plot(hist.history['accuracy'], color='b', label=\"Training accuracy\")\n",
    "    plt.plot(hist.history['val_accuracy'], color='r',label=\"Validation accuracy\")\n",
    "    plt.savefig(path + 'model_loss_hist.png')\n",
    "    plt.legend(loc = \"lower right\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_model__hist(models_hist)\n",
    "loss,acc = models.evaluate(val_ds, verbose=2)\n",
    "print(\"multi_model의 정확도: {:5.2f}%\".format(100*acc))\n",
    "print(\"multi_model의 Loss: {}\".format(loss))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 모델 불러와서 confusion matrix 그리기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 모델 불러오기\n",
    "reconstructed_model = keras.models.load_model(\"./cheakpoint/lefms_model/weights-0.9924.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 예측값 얻기\n",
    "y_pred = reconstructed_model.predict(val_ds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# one hat encoding 를 하나의 변수로 바꾸기\n",
    "new_y= []\n",
    "for val in y_test:\n",
    "    max = 0\n",
    "    cnt = 0\n",
    "    for idx, num in enumerate(val):\n",
    "        if max < num:\n",
    "            max = num\n",
    "            cnt = idx + 1\n",
    "    new_y.append(cnt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# one hat encoding 를 하나의 변수로 바꾸기\n",
    "new_y_pred = []\n",
    "for val in y_pred:\n",
    "    max = 0\n",
    "    cnt = 0\n",
    "    for idx, num in enumerate(val):\n",
    "        if max < num:\n",
    "            max = num\n",
    "            cnt = idx + 1\n",
    "    new_y_pred.append(cnt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 최종 정확도 산출\n",
    "score = reconstructed_model.evaluate(X_test, y_test, verbose=1)\n",
    "print('정답률 = ', score[1],'loss=', score[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### confusion matrix 그리기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 개수 버전\n",
    "from sklearn.metrics import classification_report, confusion_matrix, precision_score, recall_score, f1_score\n",
    "import seaborn as sns\n",
    "\n",
    "cm2 = confusion_matrix(new_y, new_y_pred)\n",
    "sns.heatmap(cm2, annot = True, fmt = 'd', cmap= 'Reds')\n",
    "plt.xlabel('predict')\n",
    "plt.ylabel('real')\n",
    "plt.xticks([0.5, 1.5, 2.5, 3.5, 4.5], ['0 = N', '1 = S', '2 = V', '3 = F', '4 = Q'])\n",
    "plt.yticks([0.5, 1.5, 2.5, 3.5, 4.5], ['0 = N', '1 = S', '2 = V', '3 = F', '4 = Q'])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# percentile 버전\n",
    "total = np.sum(cm2, axis=1)\n",
    "cm2_percentile = cm2/total[:,None]\n",
    "sns.heatmap(np.round(cm2_percentile,3), annot = True, cmap= 'Reds')\n",
    "plt.xlabel('predict')\n",
    "plt.ylabel('real')\n",
    "plt.xticks([0.5, 1.5, 2.5, 3.5, 4.5], ['0 = N', '1 = S', '2 = V', '3 = F', '4 = Q'])\n",
    "plt.yticks([0.5, 1.5, 2.5, 3.5, 4.5], ['0 = N', '1 = S', '2 = V', '3 = F', '4 = Q'])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "confusion_matrix(new_y, new_y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# classification_report 그리기\n",
    "from sklearn.metrics import classification_report\n",
    "target_names = ['0 = N', '1 = S', '2 = V', '3 = F', '4 = Q']\n",
    "print(classification_report(new_y, new_y_pred, target_names=target_names))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.7 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "6c3cabcf2f29820bdd7faae982b59d335e0d215fb5382d93f3312fa3292e9b7f"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
